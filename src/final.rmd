---
title: "Rapport final - Projet Bradley Terry"
output: html_document
---

INTRODUCTION 
____________________________

L'objectif de ce projet est d'adapter le modèle de Bradley-Terry pour prédire le résultat de matches de tennis. Nous sommes partis du modèle simple de Bradley-Terry, qui modélise le résultat de comparaisons entre plusieurs joueurs de tennis en prenant en entrée l'historique de leurs confrontations ; puis l'avons raffiné, en ajoutant plusieurs autres paramètres : le nombre de jeux marqués, la surface sur laquelle le match s'est joué, le temps écoulé depuis la rencontre. Pour chaque joueur, nous obtenons un score, qui reflète l'agrégation de ces paramètres. Cela permet de dresser un classement qui, en comparaison avec le classement ATP utilisé par la Fédération Internationale de Tennis, réflète plus les rappors de force et moins le nombre de rencontres jouées. 


LE MODÈLE DE BRADLEY-TERRY
____________________________

Dans le modèle de Bradley-Terry, chaque joueur $i$ se voit attribuer un score $r_i > 0$, d'autant plus élevé que ses performances sont bonnes. Ce score permet d'effectuer des comparaisons entre deux joueurs : la probabilité que le joueur $i$ gagne son match contre le joueur $j$ est $$r_i/(r_i + r_j)$$. 
On se place dans un univers de $d$ joueurs. Pour $1 \leqslant i, j \leqslant d$, notons $Y_{i,j}$ le nombre de matches gagnés par le joueur $i$ contre le joueur $j$, et $n_{i,j} = Y_{i,j} + Y_{j,i}$ le nombre total de matches entre les deux joueurs.

On fixe par exemple $r_1 = 1$ pour que le modèle soit identifiable. L'objectif est d'estimer le vecteur des scores $$\theta = (r_2, ..., r_d) \in (\mathbb{R}_{+}^{*})^{d-1}$$, en utilisant la méthode du maximum de vraisemblance.
Chaque variable $Y_{i,j}$ suit une loi binomiale de paramètres $$(n_{i, j}, r_i/(r_i + r_j))$$. La vraisemblance est donc donnée par 
\[ p(\theta; y_{1, 2}, ..., y_{1,d}, y_{2,3}, ..., y_{d-1,d}) = \prod_{i = 1}^{d-1} \prod_{j = i+1}^{d} \binom{n_{i,j}}{y_{i,j}} \left(\frac{r_i}{r_i+r_j}\right)^{y_{i,j}} \left(\frac{r_j}{r_i+r_j}\right)^{y_{j,i}} \]
d'où la log-vraisemblance 
\[ \ln p(\theta) = C + \sum_{i=1}^{d-1} \sum_{j=i+1}^{d} \left(Y_{i,j} \ln r_i + Y_{j,i} \ln r_j - n_{i,j} \ln(r_i + r_j)\right)\]
avec \[ C = \sum_{i=1}^{d-1} \sum_{j=i+1}^{d} \ln \binom{n_{i,j}}{Y_{i,j}} \]
Notons $$Y_{i,+} = \sum_{j \neq i} Y_{i, j}$$ le nombre total de victoires de l'individu $i$. Alors la log-vraisemblance se simplifie en
\[ \ln p(\theta) = C + \sum_{i = 1}^{d} Y_{i, +} \ln r_i - \sum_{i=1}^{d-1} \sum_{j=i+1}^{d} n_{i,j} \ln(r_i + r_j)\]
Cette fonction est concave en les $r_i$ donc il suffit de choisir les $r_i$ qui annulent son gradient. Pour $2 \leqslant i \leqslant d$ :
\[ \begin{align}
\frac{\partial \ln p(\theta)}{\partial r_i} &= \frac{Y_{i, +}}{r_i} - \sum_{j > i} \frac{n_{i,j}}{r_i + r_j} - \sum_{k < i} \frac{n_{k,i}}{r_k + r_i} \\
 &= \frac{Y_{i, +}}{r_i} - \sum_{j \neq i} \frac{n_{i,j}}{r_i + r_j}
 \end{align}
\]
car $n_{i,j} = n_{j,i}$.
On obtient donc \[ r_i = Y_{i, +} \left( \sum_{j \neq i} \frac{n_{i,j}}{r_i + r_j}\right)^{-1}\]
Cette équation permet de maximiser la log-vraisemblance de manière itérative. On initialise $\theta^{(0)} = (r_2^{(0)}, ..., r_d^{(0)})$ de manière aléatoire, par exemple en prenant tous les scores égaux à 1. Pour $t \geq 0$, on pose
\[ r_i^{(t+1)} = Y_{i, +} \left( \sum_{j \neq i} \frac{n_{i,j}}{r_i^{(t)} + r_j^{(t)}}\right)^{-1}\]
La suite $\left(\theta^{(t)}\right)_{t \geqslant 0}$ converge vers un maximiseur de la log-vraisemblance.
C'est cet algorithme itératif qui est implémenté dans la fonction bradleyt.


EXTENSION DU MODÈLE
____________________________

On peut raffiner le modèle de manière à ce qu'il ne prenne plus seulement en compte le résultat seul de chaque match, mais aussi le nombre de jeux marqués par chacun des joueurs. Le modèle estime également la pertinence des résultats, en pénalisant les données les plus anciennes. Pour cela, on lui donne en entrée les nouveaux paramètres suivants, pour chaque rencontre $1 \leqslant p \leqslant p_{i,j}$ :
-- la probabilité que l'individu $i$ marque un jeu contre l'individu $j$ est $$\alpha_i/(\alpha_i + \alpha_j)$$$
-- $g_{i,j}^p$ est le nombre de jeux joués pendant la $p$-ième rencontre entre les joueurs $i$ et $j$
-- $$\beta_{i,j}^p = \exp(-\alpha (t_{p_{i,j}} - t_{p}))$$ est une fonction décroissante du temps écoulé depuis le match $p$

On note $Y_{i,j}^p$ le nombre de jeux marqués par le joueur $i$ contre le joueur $j$ lors du match $p$, de sorte que $$Y_{j,i}^p = g_{i,j}^p - Y_{i,j}^p$$. Les observations sont maintenant le nombre de jeux marqués par les deux joueurs pour chaque match. La vraisemblance associée aux observations $y_{i,j}^p$, pour $1 \leqslant i,j \leqslant d$ et $1 \leqslant p \leqslant p_{i,j}$, est
\[ \prod_{i = 1}^{d-1} \prod_{j = i+1}^{d} \prod_{p = 1}^{p_{i,j}} \left(\binom{n_{i,j}}{y_{i,j}^p} \left(\frac{\alpha_i}{\alpha_i+\alpha_j}\right)^{g_{i,j}^p} \left(\frac{\alpha_j}{\alpha_i+\alpha_j}\right)^{g_{j,i}^p}\right)^{\beta_{i,j}^p}
\]
d'où une log-vraisemblance à nouveau de la forme
\[ \ln p(\theta) = C + \sum_{i=1}^{d-1} \sum_{j=i+1}^{d} \left(Y_{i,j} \ln \alpha_i + Y_{j,i} \ln \alpha_j - n_{i,j} \ln(\alpha_i + \alpha_j)\right)\]
avec \[ C = \sum_{i=1}^{d-1} \sum_{j=i+1}^{d} \sum_{p = 1}^{p_{i,j}} \beta_{i,j}^p \ln \binom{g_{i,j}^p}{Y_{i,j}^p} \text{ et }
n_{i,j} = \sum_{p=1}^{p_{i,j}} \beta_{i,j}^p y_{i,j}^p\]

On est donc ramené à l'étude du modèle de Bradley-Terry simple.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


PRÉPROCESSING DES DONNÉES
____________________________

Les données que nous avons récupérées se présentent sous la forme d’un fichier csv par année où chaque ligne correspond à un match du circuit professionnel de tennis. Les informations sur chaque match sont diverses : nom du vainqueur, nom du perdant, score dans chacune des manches, surface du terrain, etc.

La fonction écrite pour calculer les scores de Bradley-Terry prend en entrée une matrice dont chaque coefficient $m_{i,j}$ correspond au nombre de points marqué par le joueur $i$ contre le joueur $j$. Le travail de préparation des données consiste en extraire le score de chaque match pour remplir la matrice qui sera placée en entrée de la fonction de calcul des scores.

```{r cars}
#install.packages('BradleyTerry2')
#install.packages("stringr", dependencies=TRUE)
library(BradleyTerry2)
library(stringr)
library(data.table)

#lecture des données
d2009=read.csv("data/2009.csv")
d2010=read.csv("data/2010.csv")
d2011=read.csv("data/2011.csv")
d2012=read.csv("data/2012.csv")
d2013=read.csv("data/2013.csv")
dall<-list(d2009, d2010, d2011, d2012, d2013)
donnees<-rbindlist(dall, fill=TRUE)
donnees<-as.data.frame(donnees)

#On uniformise les noms
donnees$Winner=gsub(". ",x=donnees$Winner,".", fixed=TRUE)
donnees$Loser=gsub(". ",x=donnees$Loser,".", fixed=TRUE)
```


Dans un premier temps, quelques modifications sont à apporter au dataset.

En effet, le modèle que nous avons décidé d’utiliser ne compte pas simplement le nombre de victoires mais le nombre de jeux gagnés par chacun des adversaires. Deux colonnes sont donc rajoutées et contiennent respectivement le nombre de jeux gagnés par le vainqueur et le perdant. C'est ce que fait la fonction **aggregate_games**. Pour cela, il a été nécessaire de remplacer les données manquantes (les scores des manches non jouées) par des 0 afin de pouvoir sommer sur toutes les manches.

Nous avons également dû remplacer la date du match par le nombre d’années le séparant de l’année de référence (i.e. 2013) afin de pouvoir calculer la pondération de l’importance de chaque rencontre selon le modèle proposé. C'est ce que fait la fonction **level_date**, en passant les données au format Date depuis Factor.


```{r}

# PREPROCESSING

#on récupère le nom de tous les joueurs ayant participé à au moins 1 match et leur nombre
joueurs=union(levels(factor(donnees$Winner)), levels(factor(donnees$Loser)))
n<- length(joueurs)

#On remplace la date par le nombre d'année la séparant de 2013
level_date<-function(df){
  df$Date<-2013-year(as.Date(df$Date, format = "%d/%m/%Y"))
  return (df)
}

#On calcule le nombre de jeux gagnés par chacun des joueurs
aggregate_games<-function(df){
  df<-replace(df, is.na(df), 0)
  df$W<-df$W1+df$W2+df$W3+df$W4+df$W5
  df$L<-df$L1+df$L2+df$L3+df$L4+df$L5
  return (df)
}

prepare_df<-function(df){
  df<-level_date((df))
  df<-aggregate_games(df)
  return(df)
}

#on récupère le nombre de jeu gagnés par chaque joueur de la ligne et on les rajoute à la matrice des résultats, coefficienté par la décroissance exponentielle
fill_results<- function(line,results, alpha){
  w<-(as.numeric(line['W']) * exp(-(alpha*as.numeric(line['Date']))))
  l<-(as.numeric(line['L']) * exp(-(alpha*as.numeric(line['Date']))))
  
  results[as.character(line['Winner']),as.character(line['Loser'])] <<- as.numeric(results[as.character(line['Winner']),as.character(line['Loser'])]) + w
  
  results[as.character(line['Loser']),as.character(line['Winner'])] <<- as.numeric(results[as.character(line['Loser']),as.character(line['Winner'])]) + l
}
```

La fonction **process_surface** joue le rôle principal. Elle prend en entrée un dataframe non-préparé et un coefficient $\alpha$ qui symbolise la vitesse de décroissance de la pondération, et retourne la matrice comme attendue pour le calcul des scores de Bradley-Terry. On commence par déclarer la matrice de sortie, une matrice carrée avec chacun des joueurs ayant participé à au moins un match sur les deux axes. Ensuite, via la fonction **apply** de R on fait appel à la fonction **fill_result** sur chacune des lignes du dataframe. Celle-ci va récupérer sur la ligne le nombre de jeux gagnés par chacun des joueurs, calculer la pondération et l’ajouter dans la matrice de sortie.

Ainsi, la fonction **process_surface** prend en entrée un dataframe non préparé, le coefficient de pondération et retourne la matrice prête à être utilisée, où tous les scores ont été pondérés puis ajoutés.

```{r}
#on prépare le dataframe puis on crée la matrice des résultats que l'on remplie grace au apply
process_surface<-function(df,alpha){
  a<-df
  a<-level_date((a))
  a<-aggregate_games(a)
  
  results <<- data.frame(matrix(ncol = n, nrow = n))
  colnames(results)<<-joueurs
  rownames(results)<<-joueurs
  results<<-replace(results, is.na(results), 0)
  
  apply(a,1,function(x) fill_results(x,results,alpha))
  return(results)
}
```

Nous avons également voulu différencier les matchs selon les surfaces. Pour cela, la fonction **process_data** commence par séparer le dataframe initial en une liste contenant un dataframe par surface. On utilise ensuite **process_surface** via la fonction **lapply** afin de pouvoir préparer une matrice pour chacune des quatre surfaces.


```{r}
#on sépare les matchs selon la surface de jeu et on calcule la matrice des résultats pour chacune des surfaces
process_data<-function(df, alpha){
  X <- split(df,df$Surface)
  Y<-lapply(X,function(x) process_surface(x,alpha))
  return(Y)
}
```

Les deux fonctions de merging permettent de regrouper les résultats. **simple_merge** va simplement les sommer pour obtenir une seule matrice comme si les surfaces n’avaient jamais été prises en compte. Pour la matrice liée aux résultats d’une surface, **composed_merge** permet de prendre en compte les résultats des autres surfaces via un coefficient de pondération $\beta$. Elle retourne donc une liste contenant une matrice par surface, chacune prête à être utilisée pour le calcul des scores de Bradley-Terry.


```{r}
#simple somme des résultats de chaque surface
simple_merge<-function(df){
  y<-Reduce(`+`,df)
  return (y)
}

#on ajoute aux scores d'une surface les scores des autres, surfaces pondérés par beta
composed_merge<-function(df,beta){
  y<-simple_merge(df)
  v<-lapply(df,function(x) beta*y+(1-beta)*x)
  return (v)
}
```


Pour cette partie, la principale difficulté aura été de contourner le problème créés par le fait que R ne modifie, par défaut, que des variables locales dans les fonctions créées. Ainsi les modifications apportées à une variable définie hors de la fonction ne sont pas conservées une fois la fonction exécutée. Il aurait donc été compliqué de créer une "super-fonction" utilisant les autres afin d’effectuer tout le processus d’un coup. La solution trouvée a été de définir les nouvelles variables, au sein des fonctions, via l’opérateur **<<-**. Ce dernier définit la variable comme globale dans l’environnement actuel, ce qui permet ensuite de la modifier en exécutant les autres fonctions. On peut donc créer une matrice dans la fonction **process_surface**, la modifier dans **fill_results** et la retourner ensuite.


```{r}
#nous avons recodé à la main le calcul des log-scores par la maximisation de la vraisemblance
bradleyt = function(M){
  
  assertthat::are_equal(dim(M)[1],dim(M)[2])
  d=dim(M)[1]
  
  #we set the first score as 0
  scores = rep(1, d)
  nbMatchs = M + t(M)
  for(p in 1:100){
    scores_dup = matrix(rep(scores, d), ncol = d)
    scores_dup = sweep(scores_dup, 2, scores, '+')
    y = rowSums(M)
    coeff = rowSums(nbMatchs / scores_dup)
    scores = y / coeff
    scores[scores == 0] <- 0.001; scores[is.na(scores)] <- 0.001
  }
  return(log(scores))
  
}

```


```{r}
#process the matrix for each surface, with everygame pondered with exp(-alpha*t) (t=nombre d'années séparant de l'année actuelle)
alpha<-10
z<-process_data(donnees,alpha)

#simple sum of the results for every surface
y<-simple_merge(z)
ym=as.matrix(y)
dim(ym)

#matrixes for every surface with the score being 1*main surface score + Beta * (sum of other surfaces score). For example see w$Clay, w$Grass, w$Hard or w$Carpet
beta<-0.1
w<-composed_merge(z,beta)

scores <- bradleyt(ym)

#on  obtient le classement croissant des jouers par:
colnames(ym)[order(scores)]

# attribution of a score to each player
dim(ym)
colnames(ym)[591]
ym[591,]
ym[592,]
sum(ym[,591])
for (i in 590:592){
  print(sum(ym[i,]))
}
ym[,591]
bradleyt(ym)

# fonctions indicatrices
ind<-function(x) {
  if (x==0) {
    return(1)
  }
  return(0)
}

ind_2<-function(x) {
  if (x>0) {
    return(1)
  }
  return(0)
}

# comparaison entre les prévisions et les résultats (somme des carrés)
prediction_quality_carres<-function(scores, results) {
  d1=sapply(1:length(scores),function(i) sapply(1:length(scores),function(j) (scores[i]/(scores[i]+ scores[j]))*(1-ind(results[i,j]+ results[j,i]))))
  d2=sapply(1:length(scores),function(i) sapply(1:length(scores),function(j) results[i,j]/(results[i,j]+ results[j,i]+ind(results[i,j]+ results[j,i]))))
  d3=d1-d2
  d4=sapply(d3, function(x) x^2)
  S=(sum(d4)-(1/4)*length(scores))/2 
  return(S)
}

# comparaison entre les prévisions et les résultats (somme des valeurs absolues)
prediction_quality_valabs<-function(scores, results) {
  d1=sapply(1:length(scores),function(i) sapply(1:length(scores),function(j) (scores[i]/(scores[i]+ scores[j]))*(1-ind(results[i,j]+ results[j,i]))))
  d2=sapply(1:length(scores),function(i) sapply(1:length(scores),function(j) results[i,j]/(results[i,j]+ results[j,i]+ind(results[i,j]+ results[j,i]))))
  d3=d1-d2
  d4=sapply(d3, function(x) abs(x))
  S=(sum(d4)-(1/2)*length(scores))/2
  return(S)
}

# écart moyen entre prévision et résultat
ecart_moyen<- function(scores, results) {
  return(prediction_quality_valabs(scores, results)/sum(results))
}

# proportions de résultats conformes au classement
proportion_matchs_bien_predits<-function(scores,results) {
  den=sum(results)
  pred=sapply(1:length(scores),function(i) sapply(1:length(scores),function(j) results[i,j]*ind_2(scores[i]-scores[j])))
  num=sum(pred)
  return (num/den)
}

# tracé en fonction de alpha
fx<-prediction_quality_carres(bradleyt(simple_merge(process_data(donnees,x))),results)
plot(x=seq(0,1,length=50), y=fx)

```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
